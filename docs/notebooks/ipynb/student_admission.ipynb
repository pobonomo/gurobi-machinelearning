{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eba6234",
   "metadata": {},
   "source": [
    "# Student Enrollment\n",
    "\n",
    "In this example, we show how to reproduce the model of student enrollment from\n",
    "<cite data-cite=\"JANOS\">Bergman et.al. (2020)</cite> with Gurobi Machine\n",
    "Learning.\n",
    "\n",
    "This model was developed in the context of the development of\n",
    "[Janos](https://github.com/INFORMSJoC/2020.1023), a toolkit similar to Gurobi\n",
    "Machine Learning to integrate ML models and Mathematical Optimization.\n",
    "\n",
    "This example illustrates in particular how to use the logistic regression and\n",
    "tune the piecewise-linear approximation of the logistic function.\n",
    "\n",
    "We also show how to deal with fixed features in the optimization model using\n",
    "pandas data frames.\n",
    "\n",
    "In this model, data of students admissions in a college is used to predict the\n",
    "probability that a student enrolls to the college.\n",
    "\n",
    "The data has 3 features: the SAT and GPA scores of each student, and the\n",
    "scholarship (or merit) that was offered to each student. Finally, it is known if\n",
    "each student decided to join the college or not.\n",
    "\n",
    "Based on this data a logistic regression is trained to predict the probability\n",
    "that a student joins the college.\n",
    "\n",
    "Using this regression model, <cite data-cite=\"JANOS\">Bergman et.al.\n",
    "(2020)</cite> proposes the following student enrollment problem. The Admission\n",
    "Office has data for SAT and GPA scores of the admitted students for the incoming\n",
    "class, and they would want to offer scholarships to students with the goal of\n",
    "maximizing the expected number of students that enroll in the college. There is\n",
    "a total of $n$ students that are admitted. The maximal budget for the sum of all\n",
    "scholarships offered is $0.2 n \\, \\text{K\\$}$ and each student can be offered a\n",
    "scholarship of at most $2.5 \\, \\text{K\\$}$.\n",
    "\n",
    "This problem can be expressed as a mathematical optimization problem as follows.\n",
    "Two vectors of decision variables $x$ and $y$ of dimension $n$ are used to model\n",
    "respectively the scholarship offered to each student in $\\text{K\\$}$ and the\n",
    "probability that they join. Denoting by $g$ the prediction function for the\n",
    "probability of the logistic regression we then have for each student $i$:\n",
    "\n",
    "$$ y_i = g(x_i, SAT_i, GPA_i), $$\n",
    "\n",
    "with $SAT_i$ and $GPA_i$ the (known) SAT and GPA score of each student.\n",
    "\n",
    "The objective is to maximize the sum of the $y$ variables and the budget\n",
    "constraint imposes that the sum of the variables $x$ is less or equal to $0.2n$.\n",
    "Also, each variable $x_i$ is between 0 and 2.5.\n",
    "\n",
    "The full model then reads:\n",
    "\n",
    "$$ \\begin{aligned} &\\max \\sum_{i=1}^n y_i \\\\\n",
    "&\\text{subject to:}\\\\\n",
    "&\\sum_{i=1}^n x_i \\le 0.2*n,\\\\\n",
    "&y_i = g(x_i, SAT_i, GPA_i) & & i = 1, \\ldots, n,\\\\\n",
    "& 0 \\le x \\le 2.5. \\end{aligned} $$\n",
    "\n",
    "Note that in this example differently to <cite data-cite=\"JANOS\">Bergman et.al.\n",
    "(2020)</cite> we scale the features for the regression. Also, to fit in Gurobi's\n",
    "limited size license we only consider the problem where $n=250$.\n",
    "\n",
    "We note also that the model may differ from the objectives of Admission Offices\n",
    "and don't encourage its use in real life. The example is for illustration\n",
    "purposes only.\n",
    "\n",
    "## Importing packages and retrieving the data\n",
    "\n",
    "We import the necessary packages. Besides the usual (`numpy`, `gurobipy`,\n",
    "`pandas`), for this we will use Scikit-learn's Pipeline, StandardScaler and\n",
    "LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9961b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import sys\n",
    "import gurobipy as gp\n",
    "\n",
    "from gurobi_ml import add_predictor_constr\n",
    "\n",
    "import gurobipy_pandas as gppd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a96d64",
   "metadata": {},
   "source": [
    "We now retrieve the historical data used to build the regression from Janos\n",
    "repository.\n",
    "\n",
    "The features we use for the regression are `\"merit\"` (scholarship), `\"SAT\"` and\n",
    "`\"GPA\"` and the target is `\"enroll\"`. We store those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24154c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL for retrieving data\n",
    "janos_data_url = \"https://raw.githubusercontent.com/INFORMSJoC/2020.1023/master/data/\"\n",
    "historical_data = pd.read_csv(\n",
    "    janos_data_url + \"college_student_enroll-s1-1.csv\", index_col=0\n",
    ")\n",
    "\n",
    "# classify our features between the ones that are fixed and the ones that will be\n",
    "# part of the optimization problem\n",
    "features = [\"merit\", \"SAT\", \"GPA\"]\n",
    "target = \"enroll\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a87740e",
   "metadata": {},
   "source": [
    "## Fit the logistic regression\n",
    "\n",
    "For the regression, we use a pipeline with a standard scaler and a logistic\n",
    "regression. We build it using the `make_pipeline` from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8a43ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run our regression\n",
    "scaler = StandardScaler()\n",
    "regression = LogisticRegression(random_state=1)\n",
    "pipe = make_pipeline(scaler, regression)\n",
    "pipe.fit(X=historical_data.loc[:, features], y=historical_data.loc[:, target])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4236c46e",
   "metadata": {},
   "source": [
    "### Optimization Model\n",
    "\n",
    "We now turn to building the mathematical optimization model for Gurobi.\n",
    "\n",
    "First, retrieve the data for the new students. We won't use all the data there,\n",
    "we randomly pick 250 students from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve new data used to build the optimization problem\n",
    "studentsdata = pd.read_csv(janos_data_url + \"college_applications6000.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "nstudents = 250\n",
    "\n",
    "# Select randomly nstudents in the data\n",
    "studentsdata = studentsdata.sample(nstudents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861392fc",
   "metadata": {},
   "source": [
    "We can now create the our model.\n",
    "\n",
    "Since our data is in pandas data frames, we use the package gurobipy-pandas to help create the variables directly using the index of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6222f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with classical part of the model\n",
    "m = gp.Model()\n",
    "\n",
    "# The y variables are modeling the probability of enrollment of each student. They are indexed by students data\n",
    "y = gppd.add_vars(m, studentsdata, name='enroll_probability')\n",
    "\n",
    "# We add to studentsdata a column of variables to model the \"merit\" feature. Those variable are between 0 and 2.5.\n",
    "# They are added directly to the data frame using the gppd extension.\n",
    "studentsdata = studentsdata.gppd.add_vars(m, lb=0.0, ub=2.5, name='merit')\n",
    "\n",
    "# We denote by x the (variable) \"merit\" feature\n",
    "x = studentsdata.loc[:, \"merit\"]\n",
    "\n",
    "# Make sure that studentsdata contains only the features column and in the right order\n",
    "studentsdata = studentsdata.loc[:, features]\n",
    "\n",
    "m.update()\n",
    "\n",
    "# Let's look at our features dataframe for the optimization\n",
    "studentsdata[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a83662",
   "metadata": {},
   "source": [
    "We add the objective and the budget constraint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21833e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.setObjective(y.sum(), gp.GRB.MAXIMIZE)\n",
    "\n",
    "m.addConstr(x.sum() <= 0.2 * nstudents)\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba0719c",
   "metadata": {},
   "source": [
    "Finally, we insert the constraints from the regression. In this model we want to\n",
    "have use the probability estimate of a student joining the college, so we choose\n",
    "the parameter `output_type` to be `\"probability_1\"`. Note that due to the shapes\n",
    "of the `studentsdata` data frame and `y`, this will insert one regression constraint\n",
    "for each student.\n",
    "\n",
    "With the `print_stats` function we display what was added to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr = add_predictor_constr(\n",
    "    m, pipe, studentsdata, y, output_type=\"probability_1\"\n",
    ")\n",
    "\n",
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb51817",
   "metadata": {},
   "source": [
    "We can now optimize the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efffd1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d5c78",
   "metadata": {},
   "source": [
    "Remember that for the logistic regression, Gurobi does a piecewise-linear\n",
    "approximation of the logistic function. We can therefore get some significant\n",
    "errors when comparing the results of the Gurobi model with what is predicted by\n",
    "the regression.\n",
    "\n",
    "We print the error using [get_error](../api/AbstractPredictorConstr.rst#gurobi_ml.modeling.base_predictor_constr.AbstractPredictorConstr.get_error) (note that we take the maximal error\n",
    "over all input vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9a2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Maximum error in approximating the regression {:.6}\".format(\n",
    "        np.max(pred_constr.get_error())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8fa4d3",
   "metadata": {},
   "source": [
    "The error we get might be considered too large, but we can use Gurobi parameters\n",
    "to tune the piecewise-linear approximation made by Gurobi (at the expense of a\n",
    "harder models).\n",
    "\n",
    "The specific parameters are explained in the documentation of [Functions\n",
    "Constraints](https://www.gurobi.com/documentation/9.1/refman/constraints.html#subsubsection:GenConstrFunction)\n",
    "in Gurobi's manual.\n",
    "\n",
    "We can pass those parameters to the\n",
    "[add_predictor_constr](../api/AbstractPredictorConstr.rst#gurobi_ml.add_predictor_constr)\n",
    "function in the form of a dictionary with the keyword parameter\n",
    "`pwd_attributes`.\n",
    "\n",
    "Now we want a more precise solution, so we remove the current constraint, add a\n",
    "new one that does a tighter approximation and resolve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8706d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr.remove()\n",
    "\n",
    "pwl_attributes = {\n",
    "    \"FuncPieces\": -1,\n",
    "    \"FuncPieceLength\": 0.01,\n",
    "    \"FuncPieceError\": 1e-5,\n",
    "    \"FuncPieceRatio\": -1.0,\n",
    "}\n",
    "pred_constr = add_predictor_constr(\n",
    "    m, pipe, studentsdata, y, output_type=\"probability_1\", pwl_attributes=pwl_attributes\n",
    ")\n",
    "\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1c7700",
   "metadata": {},
   "source": [
    "We can see that the error has been reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d2ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Maximum error in approximating the regression {:.6}\".format(\n",
    "        np.max(pred_constr.get_error())\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e802a077",
   "metadata": {},
   "source": [
    "Finally note that we can directly get the input values for the regression in a solution as a pandas dataframe using input_values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b5c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr.input_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c54d0",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "Copyright © 2023 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb///ipynb,myst///md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "license": {
   "full_text": "# Copyright © 2023 Gurobi Optimization, LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================="
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
