{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e896d9c",
   "metadata": {},
   "source": [
    "# Adversarial Machine Learning\n",
    "\n",
    "In this example, we show how to use Gurobi Machine Learning to construct an\n",
    "adversarial example for a trained neural network.\n",
    "\n",
    "We use the MNIST handwritten digit database (http://yann.lecun.com/exdb/mnist/)\n",
    "for this example.\n",
    "\n",
    "For this problem, we are given a trained neural network and one well classified\n",
    "example $\\bar x$. Our goal is to construct another example $x$ _close to_ $\\bar\n",
    "x$ that is classified with a different label.\n",
    "\n",
    "For the hand digit recognition problem, the input is a grayscale image of $28\n",
    "\\times 28$ ($=784$) pixels and the output is a vector of length 10 (each entry\n",
    "corresponding to a digit). We denote the output vector by $y$. The image is\n",
    "classified according to the largest entry of $y$.\n",
    "\n",
    "For the training example, assume that coordinate $l$ of the output vector is\n",
    "the one with the largest value giving the correct label. We pick a coordinate\n",
    "corresponding to another label, denoted $w$, and we want the difference between\n",
    "$y_w - y_l$ to be as large as possible.\n",
    "\n",
    "If we can find a solution where this difference is positive, then $x$ is a\n",
    "_counter-example_ receiving a different label. If instead we can show that\n",
    "the difference is never positive, no such example exists.\n",
    "\n",
    "Here, we use the $l1-$norm $|| x - \\bar x||_1$ to define the neighborhood with its size\n",
    "defined by a fixed parameter $\\delta$:\n",
    "\n",
    "$$ || x - \\bar x ||_1 \\le \\delta. $$\n",
    "\n",
    "Denoting by $g$ the prediction function of the neural network, the full\n",
    "optimization model reads:\n",
    "\n",
    "$$ \\begin{aligned} &\\max y_w - y_l \\\\\n",
    "&\\text{subject to:}\\\\\n",
    "&|| x - \\bar x ||_1 \\le \\delta,\\\\\n",
    "& y = g(x). \\end{aligned} $$\n",
    "\n",
    "\n",
    "Note that our model is inspired by <cite data-cite=\"fischetti_jo_2018\">Fischet al.\n",
    "(2018)</cite>.\n",
    "\n",
    "## Imports and loading data\n",
    "\n",
    "First, we import the required packages for this example.\n",
    "\n",
    "In addition to the usual packages, we will need `matplotlib` to plot the digits,\n",
    "and `joblib` to load a pre-trained network and part of the training data.\n",
    "\n",
    "Note that from the `gurobi_ml` package we need to use directly the\n",
    "`add_mlp_regressor_constr` function for reasons that will be clarified later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f31b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "import numpy as np\n",
    "from joblib import load\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from gurobi_ml.sklearn import add_mlp_regressor_constr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648b788",
   "metadata": {},
   "source": [
    "We load a neural network that was pre-trained with Scikit-learn's MLPRegressor.\n",
    "The network is small (2 hidden layers of 50 neurons), finding a counter\n",
    "example shouldn't be too difficult.\n",
    "\n",
    "We also load the first 100 training examples of the MNIST dataset that we saved\n",
    "to avoid having to reload the full data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d4336e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained network and the examples\n",
    "mnist_data = load(\"../../../tests/predictors/mnist__mlpclassifier.joblib\")\n",
    "nn = mnist_data[\"predictor\"]\n",
    "X = mnist_data[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011e6fd4",
   "metadata": {},
   "source": [
    "## Choose an example and set labels\n",
    "\n",
    "Now we choose an example. Here we chose arbitrarily example 26. We plot the\n",
    "example and verify if it is well predicted by calling the `predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cdafea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an example\n",
    "exampleno = 26\n",
    "example = X[exampleno : exampleno + 1, :]\n",
    "\n",
    "plt.imshow(example.reshape((28, 28)), cmap=\"gray\")\n",
    "\n",
    "print(f\"Predicted label {nn.predict(example)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae667df8",
   "metadata": {},
   "source": [
    "To set up the objective function of the optimization model, we also need to find a\n",
    "wrong label.\n",
    "\n",
    "We use `predict_proba` to get the weight given by the neural\n",
    "network to each label.\n",
    "We then use `numpy`'s `argsort` function to get the labels sorted by\n",
    "their weight. The right label is then the last element in the list, and we pick\n",
    "the next to last element as the wrong label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b58db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_prob = nn.predict_proba(example)\n",
    "sorted_labels = np.argsort(ex_prob)[0]\n",
    "right_label = sorted_labels[-1]\n",
    "wrong_label = sorted_labels[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc3dc61",
   "metadata": {},
   "source": [
    "## Building the optimization model\n",
    "\n",
    "Now all the data is gathered, and we proceed to building the optimization\n",
    "model.\n",
    "\n",
    "We create a matrix variable `x` corresponding to the new input of the\n",
    "neural network we want to compute and a `y` matrix variable for the output of the\n",
    "neural network. Those variables should have respectively the shape of the\n",
    "example we picked and the shape of the return value of `predict_proba`.\n",
    "\n",
    "We need additional variables to model the $l1-$norm constraint. Namely, for\n",
    "each pixel in the image, we need to measure the absolute difference between $x$\n",
    "and $\\bar x$. The corresponding matrix variable has the same shape as `x`.\n",
    "\n",
    "We set the objective which is to maximize the difference between the\n",
    "_wrong_ label and the _right_ label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd31f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = gp.Model()\n",
    "delta = 5\n",
    "\n",
    "x = m.addMVar(example.shape, lb=0.0, ub=1.0, name=\"x\")\n",
    "y = m.addMVar(ex_prob.shape, lb=-gp.GRB.INFINITY, name=\"y\")\n",
    "\n",
    "abs_diff = m.addMVar(example.shape, lb=0, ub=1, name=\"abs_diff\")\n",
    "\n",
    "m.setObjective(y[0, wrong_label] - y[0, right_label], gp.GRB.MAXIMIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1be8d01",
   "metadata": {},
   "source": [
    "The $l1-$norm constraint is formulated with:\n",
    "\n",
    "$$ \\eta \\ge x - \\bar x \\\\\n",
    "\\eta \\ge \\bar x - x \\\\\n",
    "\\sum \\eta \\le \\delta $$\n",
    "\n",
    "With $\\eta$ denoting the `absdiff` variables.\n",
    "\n",
    "Those constraints are naturally expressed with Gurobi's Matrix API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550c78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bound on the distance to example in norm-1\n",
    "m.addConstr(abs_diff >= x - example)\n",
    "m.addConstr(abs_diff >= -x + example)\n",
    "m.addConstr(abs_diff.sum() <= delta)\n",
    "\n",
    "# Update the model\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c579b",
   "metadata": {},
   "source": [
    "Finally, we insert the neural network in the `gurobipy` model to link `x` and\n",
    "`y`.\n",
    "\n",
    "Note that this case is not as straightforward as others. The reason is that the\n",
    "neural network is trained for classification with a `\"softmax\"` activation in\n",
    "the last layer. But in this model we are using the network without activation in\n",
    "the last layer.\n",
    "\n",
    "For this reason, we change manually the last layer activation before adding the\n",
    "network to the Gurobi model.\n",
    "\n",
    "Also, we use the function\n",
    "[add_mlp_regressor_constr](../api/MlpRegressorConstr.rst#gurobi_ml.sklearn.add_mlp_regressor_constr)\n",
    "directly. The network being actually for classification (i.e. of type\n",
    "`MLPClassifier`) the\n",
    "[add_predictor_constr](../api/AbstractPredictorConstr.rst#gurobi_ml.add_predictor_constr)\n",
    "function would not handle it automatically.\n",
    "\n",
    "In the output, there is a warning about adding constraints with\n",
    "very small coefficients that are ignored. Neural-networks often contain very\n",
    "small coefficients in their expressions. Any coefficient with an absolute value\n",
    "smaller than $10^{-13}$ is ignored by Gurobi. This may result in slightly\n",
    "different predicted values but should be negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bafec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change last layer activation to identity\n",
    "nn.out_activation_ = \"identity\"\n",
    "# Code to add the neural network to the constraints\n",
    "pred_constr = add_mlp_regressor_constr(m, nn, x, y)\n",
    "\n",
    "# Restore activation\n",
    "nn.out_activation_ = \"softmax\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4ab7e2",
   "metadata": {},
   "source": [
    "The model should be complete. We print the statistics of what was added to\n",
    "insert the neural network into the optimization model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab19c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_constr.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bdc72c",
   "metadata": {},
   "source": [
    "## Solving the model\n",
    "\n",
    "We now turn to solving the optimization model. Solving the adversarial problem,\n",
    "as we formulated it above, doesn't actually require computing a provably optimal\n",
    "solution. Instead, we need to either:\n",
    "\n",
    "   - find a feasible solution with a positive objective cost (i.e. a\n",
    "     counter-example), or\n",
    "   - prove that there is no solution of positive cost (i.e. no counter-example\n",
    "     in the neighborhood exists).\n",
    "\n",
    " We can use Gurobi parameters to limit the optimization to answer those\n",
    " questions: setting\n",
    " [BestObjStop](https://www.gurobi.com/documentation/current/refman/bestobjstop.html#parameter:BestObjStop)\n",
    " to 0.0 will stop the optimizer if a counter-example is found, setting\n",
    " [BestBdStop](https://www.gurobi.com/documentation/current/refman/bestobjstop.html#parameter:BestBdStop)\n",
    " to 0.0 will stop the optimization if the optimizer has shown there is no\n",
    " counter-example.\n",
    "\n",
    "We set the two parameters and optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3335c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.Params.BestBdStop = 0.0\n",
    "m.Params.BestObjStop = 0.0\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db770c9-d4e6-4f69-9b76-cd6eab88a024",
   "metadata": {},
   "source": [
    "## Add bounds on layer output of layer 1\n",
    "\n",
    "This is for illustration purposes to show it can be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e5e17-cfec-46dd-83f5-8efa32959f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First look at the values of the output in layer 1\n",
    "pred_constr._layers[1].output.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08468951-bb01-4f22-8f3c-f0f127ae93f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We bound it to 5 (arbitrarily)\n",
    "pred_constr._layers[1].output.UB = 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b915f5-16b2-41ee-9343-c8342b81d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve the model\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0281264c-a8cf-4c1b-8f57-a970ae9b144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the values of the output in layer 1 again\n",
    "pred_constr._layers[1].output.X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829a9865",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Normally, for the example and $\\delta$ we chose, a counter example that gets the\n",
    "wrong label is found. We finish this notebook by plotting the counter example\n",
    "and printing how it is classified by the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c2abc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x.X.reshape((28, 28)), cmap=\"gray\")\n",
    "\n",
    "print(f\"Solution is classified as {nn.predict(x.X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a6d207",
   "metadata": {
    "nbsphinx": "hidden"
   },
   "source": [
    "Copyright © 2023 Gurobi Optimization, LLC"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb///ipynb,myst///md:myst"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "license": {
   "full_text": "# Copyright © 2023 Gurobi Optimization, LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n# =============================================================================="
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
